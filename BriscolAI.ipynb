{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPheU5+HJF+NFYF9vMudUBQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IGieckI/BriscolAI/blob/main/BriscolAI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random"
      ],
      "metadata": {
        "id": "zT1ofZKnU84E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Card:\n",
        "    def __init__(self, rank, seed):\n",
        "        self.rank = rank\n",
        "        self.seed = seed\n",
        "\n",
        "    def __str__(self):\n",
        "        return f\"{self.rank} of {self.seed}\"\n",
        "\n",
        "    def get_value(self):\n",
        "        \"\"\"\n",
        "        Get the point value of the card based on its rank\n",
        "        \"\"\"\n",
        "        point_values = {\n",
        "            \"Ace\": 11,\n",
        "            \"Two\": 0,\n",
        "            \"Three\": 10,\n",
        "            \"Four\": 0,\n",
        "            \"Five\": 0,\n",
        "            \"Six\": 0,\n",
        "            \"Seven\": 0,\n",
        "            \"Knave\": 2,\n",
        "            \"Knight\": 3,\n",
        "            \"King\": 4,\n",
        "        }\n",
        "        return point_values.get(self.rank)\n",
        "\n",
        "    def compare_cards(self, other_card):\n",
        "        \"\"\"\n",
        "        Compare two cards of the same seed to determine the winner based on their ranks\n",
        "\n",
        "        Args:\n",
        "            other_card : Card, The other card to compare\n",
        "\n",
        "        Returns:\n",
        "            Card: The winner card\n",
        "        \"\"\"\n",
        "        if self.get_point_value() > other_card.get_point_value():\n",
        "            return self\n",
        "        else:\n",
        "            return other_card\n",
        "\n",
        "def create_deck():\n",
        "    ranks = [\"Ace\", \"Two\", \"Three\", \"Four\", \"Five\", \"Six\", \"Seven\", \"Knave\", \"Knight\", \"King\"]\n",
        "    seeds = [\"Cups\", \"Denari\", \"Swords\", \"Sticks\"]\n",
        "    deck = [Card(rank, seed) for rank in ranks for seed in seeds]\n",
        "    return deck"
      ],
      "metadata": {
        "id": "uHxMGD3qfN4z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Briscola():\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        Generate the deck, choose a briscola and give three cards each player\n",
        "        \"\"\"\n",
        "        deck = create_deck()\n",
        "\n",
        "        ai_hand = []\n",
        "        p2_hand = []\n",
        "\n",
        "        briscola = self.draw_card()\n",
        "\n",
        "        ai_hand.append(self.draw_card())\n",
        "        ai_hand.append(self.draw_card())\n",
        "        ai_hand.append(self.draw_card())\n",
        "\n",
        "        p2_hand.append(self.draw_card())\n",
        "        p2_hand.append(self.draw_card())\n",
        "        p2_hand.append(self.draw_card())\n",
        "\n",
        "        p1_score, p2_score = 0, 0\n",
        "\n",
        "        self.state = {\"ai_hand\": ai_hand,\n",
        "                      \"briscola\": briscola,\n",
        "                      \"played_card\": None,\n",
        "                      \"turn\": \"ai\" if random.randint(0, 1) == 0 else \"player\",\n",
        "                      \"ai_score\": 0,\n",
        "                      \"player_score\": 0}\n",
        "        self.actions = (\"card1\", \"card2\", \"card3\")\n",
        "\n",
        "        init_state = self.state.copy()\n",
        "        self.history = [init_state]\n",
        "\n",
        "    def draw_card(self):\n",
        "        \"\"\"\n",
        "        Each player draw from the deck taking out cards from the deck list\n",
        "        \"\"\"\n",
        "        if len(self.deck) == 0:\n",
        "          return []\n",
        "\n",
        "        if len(self.deck) == 1 and self.briscola not in self.deck:\n",
        "          self.deck.append(self.briscola)\n",
        "\n",
        "        return self.deck.pop(0)\n",
        "\n",
        "    def fight(self, first_card, second_card):\n",
        "        \"\"\"\n",
        "        Tells who win between the two cards\n",
        "\n",
        "        Args:\n",
        "            first_card : Card, first card played\n",
        "            second_card : Card, second card played\n",
        "\n",
        "        Returns:\n",
        "            Card : The winner Card\n",
        "        \"\"\"\n",
        "\n",
        "        if first_card.seed == second_card.seed:\n",
        "          return first_card.compare_cards(second_card)\n",
        "\n",
        "        if first_card.seed == self.briscola.seed:\n",
        "          return first_card\n",
        "\n",
        "        if second_card.seed == self.briscola.seed:\n",
        "          return second_card\n",
        "\n",
        "        return first_card\n",
        "\n",
        "    def step(self, action):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            action : int, the action to pick (0, 1, 2)\n",
        "\n",
        "        Returns:\n",
        "            new_state : int, new state reached given the picked action (index in history list)\n",
        "            reward : int, the reward we get in this new state\n",
        "        \"\"\"\n",
        "        prev_state = self.state.copy()\n",
        "\n",
        "        if self.state[\"turn\"] == \"ai\":\n",
        "            ai_action = action\n",
        "            ai_card = self.state[\"ai_hand\"][ai_action]\n",
        "\n",
        "\n",
        "            # Determine the optimal card to play against the player's card\n",
        "            player_card = self.state[\"played_card\"][1]\n",
        "            ai_card_index = self.state[\"ai_hand\"].index(ai_card)\n",
        "            optimal_card_index = None\n",
        "            best_score_diff = -float(\"inf\")\n",
        "\n",
        "            for i, card in enumerate(self.state[\"ai_hand\"]):\n",
        "                score_diff = card.compare_cards(player_card)\n",
        "                if score_diff > best_score_diff:\n",
        "                    best_score_diff = score_diff\n",
        "                    optimal_card_index = i\n",
        "\n",
        "            # Retrieve the card chosen as the optimal one\n",
        "            ai_card = self.state[\"ai_hand\"].pop(optimal_card_index)\n",
        "\n",
        "            # Determine the winner of the fight and update scores accordingly\n",
        "            winner = self.fight(ai_card, player_card)\n",
        "            if winner == ai_card:\n",
        "                self.state[\"ai_score\"] += (ai_card.get_value() + player_card.get_value())\n",
        "            elif winner == player_card:\n",
        "                self.state[\"player_score\"] += (ai_card.get_value() + player_card.get_value())\n",
        "\n",
        "            # Update the played_card and turn in the state\n",
        "            self.state[\"played_card\"] = (ai_card, player_card)\n",
        "            self.state[\"turn\"] = \"player\"\n",
        "\n",
        "        else:\n",
        "            player_action = action\n",
        "\n",
        "            # Retrieve the card played by the player\n",
        "            player_card = self.state[\"ai_hand\"][int(player_action[-1]) - 1]\n",
        "\n",
        "            # Determine the optimal card to play against the player's card\n",
        "            ai_card = self.state[\"played_card\"][0]\n",
        "            ai_card_index = self.state[\"ai_hand\"].index(ai_card)\n",
        "            optimal_card_index = None\n",
        "            best_score_diff = -float(\"inf\")\n",
        "\n",
        "            for i, card in enumerate(self.state[\"ai_hand\"]):\n",
        "                score_diff = card.compare_cards(player_card)\n",
        "                if score_diff > best_score_diff:\n",
        "                    best_score_diff = score_diff\n",
        "                    optimal_card_index = i\n",
        "\n",
        "            # Retrieve the card chosen as the optimal one\n",
        "            ai_card = self.state[\"ai_hand\"].pop(optimal_card_index)\n",
        "\n",
        "            # Determine the winner of the fight and update scores accordingly\n",
        "            winner = self.fight(ai_card, player_card)\n",
        "            if winner == ai_card:\n",
        "                self.state[\"ai_score\"] += 1\n",
        "            elif winner == player_card:\n",
        "                self.state[\"player_score\"] += 1\n",
        "\n",
        "            self.state[\"played_card\"] = (ai_card, player_card)\n",
        "            self.state[\"turn\"] = \"ai\"\n",
        "\n",
        "        self.state[\"ai_hand\"].append(self.draw_card())\n",
        "        self.state[\"ai_hand\"].append(self.draw_card())\n",
        "\n",
        "        # Check if the game is over\n",
        "        if len(self.state[\"ai_hand\"]) == 0:\n",
        "            if self.state[\"ai_score\"] > self.state[\"player_score\"]:\n",
        "                reward = 1\n",
        "            elif self.state[\"ai_score\"] < self.state[\"player_score\"]:\n",
        "                reward = -1\n",
        "            else:\n",
        "                reward = 0\n",
        "\n",
        "            self.state[\"final_ai_score\"] = self.state[\"ai_score\"]\n",
        "            self.state[\"final_player_score\"] = self.state[\"player_score\"]\n",
        "\n",
        "            self.history.append(self.state.copy())\n",
        "\n",
        "            # Return \"terminal\" as the new state to indicate the end of the game\n",
        "            return \"terminal\", reward\n",
        "\n",
        "        # Add the new state to the history\n",
        "        self.history.append(self.state.copy())\n",
        "\n",
        "        # Calculate the reward as the difference in scores between the current and previous states\n",
        "        reward = self.state[\"ai_score\"] - prev_state[\"ai_score\"]\n",
        "\n",
        "        # Find the index of the new state in the history list\n",
        "        new_state = self.history.index(self.state)\n",
        "\n",
        "        return new_state, reward\n",
        "\n"
      ],
      "metadata": {
        "id": "KGrs0u20hn6k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class RLModel:\n",
        "    def __init__(self, env, actions, learning_rate=0.1, discount_factor=0.9, epsilon=1.0, max_epsilon=1.0, min_epsilon=0.01, decay_rate=0.01):\n",
        "        self.env = env\n",
        "        self.actions = actions\n",
        "        self.learning_rate = learning_rate\n",
        "        self.discount_factor = discount_factor\n",
        "        self.epsilon = epsilon\n",
        "        self.max_epsilon = max_epsilon\n",
        "        self.min_epsilon = min_epsilon\n",
        "        self.decay_rate = decay_rate\n",
        "        self.Q = np.zeros([len(env.history), len(actions)])\n",
        "\n",
        "    def choose_action(self, state):\n",
        "        if np.random.uniform(0, 1) > self.epsilon:\n",
        "            action = np.argmax(self.Q[state, :])\n",
        "        else:\n",
        "            action = np.random.choice(self.actions)\n",
        "        return action\n",
        "\n",
        "    def update_q_table(self, state, action, new_state, reward):\n",
        "        self.Q[state, action] = self.Q[state, action] + self.learning_rate * (reward + self.discount_factor * np.max(self.Q[new_state, :]) - self.Q[state, action])\n",
        "\n",
        "    def decay_epsilon(self, episode):\n",
        "        self.epsilon = self.min_epsilon + (self.max_epsilon - self.min_epsilon) * np.exp(-self.decay_rate * episode)\n",
        "\n",
        "    def train(self, num_episodes):\n",
        "        for episode in range(num_episodes):\n",
        "            state = len(self.env.history) - 1\n",
        "            done = False\n",
        "            total_reward = 0\n",
        "\n",
        "            while not done:\n",
        "                action = self.choose_action(state)\n",
        "                new_state, reward = self.env.step(self.actions[action])\n",
        "                total_reward += reward\n",
        "\n",
        "                self.update_q_table(state, action, new_state, reward)\n",
        "\n",
        "                state = len(self.env.history) - 1 if new_state == \"terminal\" else new_state\n",
        "\n",
        "                if new_state == \"terminal\":\n",
        "                    done = True\n",
        "\n",
        "            self.decay_epsilon(episode)\n",
        "\n",
        "            if episode % 1000 == 0:\n",
        "                print(\"Episode:\", episode, \"Total Reward:\", total_reward)\n",
        "\n",
        "# Initialize the environment and RL model\n",
        "env = Briscola()\n",
        "rl_model = RLModel(env, actions=(0, 1))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "xowSVoUWgeN4",
        "outputId": "c5cf203e-3b8e-463a-d215-f40211164b88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-c898efb8522d>\u001b[0m in \u001b[0;36m<cell line: 20>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# Training loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepisode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_episodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBriscola\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-4b89c7c3d789>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mp2_hand\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mbriscola\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw_card\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mai_hand\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw_card\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-4b89c7c3d789>\u001b[0m in \u001b[0;36mdraw_card\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mEach\u001b[0m \u001b[0mplayer\u001b[0m \u001b[0mdraw\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdeck\u001b[0m \u001b[0mtaking\u001b[0m \u001b[0mout\u001b[0m \u001b[0mcards\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdeck\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \"\"\"\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeck\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Briscola' object has no attribute 'deck'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_episodes = 10000\n",
        "rl_model.train(num_episodes)\n"
      ],
      "metadata": {
        "id": "BbsHoNhc0Fzg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}