{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01menum\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Enum\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from enum import Enum\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import random\n",
    "\n",
    "class Card:\n",
    "    \"\"\"\n",
    "    Game card class\n",
    "    \"\"\"\n",
    "    def __init__(self, rank: int, seed: int):\n",
    "        self.rank = int(rank)\n",
    "        self.seed = int(seed)\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"{self.get_rank()} of {self.get_seed()}\"\n",
    "\n",
    "    def __hash__(self):\n",
    "        return self.seed * 10 + self.rank\n",
    "\n",
    "    def get_value(self) -> int:\n",
    "        \"\"\"\n",
    "        Get the point value of the card based on its rank\n",
    "        \"\"\"\n",
    "        point_values = {\n",
    "            0: 11,\n",
    "            1: 0,\n",
    "            2: 10,\n",
    "            3: 0,\n",
    "            4: 0,\n",
    "            5: 0,\n",
    "            6: 0,\n",
    "            7: 2,\n",
    "            8: 3,\n",
    "            9: 4,\n",
    "        }\n",
    "        return point_values.get(self.rank, 0)\n",
    "\n",
    "    @staticmethod\n",
    "    def get_value_from_hash(card_hash: int) -> int:\n",
    "        \"\"\"\n",
    "        Get the point value of the card based on its rank from hash\n",
    "        \"\"\"\n",
    "        point_values = {\n",
    "            0: 11,\n",
    "            1: 0,\n",
    "            2: 10,\n",
    "            3: 0,\n",
    "            4: 0,\n",
    "            5: 0,\n",
    "            6: 0,\n",
    "            7: 2,\n",
    "            8: 3,\n",
    "            9: 4,\n",
    "        }\n",
    "        return point_values[card_hash % 10]\n",
    "\n",
    "    def get_rank(self) -> str:\n",
    "        \"\"\"\n",
    "        Get the rank of the card as string\n",
    "        \"\"\"\n",
    "        ranks = {\n",
    "            0: \"Ace\",\n",
    "            1: \"Two\",\n",
    "            2: \"Three\",\n",
    "            3: \"Four\",\n",
    "            4: \"Five\",\n",
    "            5: \"Six\",\n",
    "            6: \"Seven\",\n",
    "            7: \"Knave\",\n",
    "            8: \"Knight\",\n",
    "            9: \"King\"\n",
    "        }\n",
    "        return ranks.get(self.rank, \"Unknown\")\n",
    "\n",
    "    def get_seed(self) -> str:\n",
    "        \"\"\"\n",
    "        Get the seed of the card as string\n",
    "        \"\"\"\n",
    "        seeds = {\n",
    "            0: \"Cups\",\n",
    "            1: \"Denari\",\n",
    "            2: \"Swords\",\n",
    "            3: \"Sticks\"\n",
    "        }\n",
    "        return seeds.get(self.seed, \"Unknown\")\n",
    "\n",
    "    def compare_cards(self, other_card: 'Card') -> 'Card':\n",
    "        \"\"\"\n",
    "        Compare two cards to determine the winner ONLY based on their ranks, NOT the seed\n",
    "        \"\"\"\n",
    "        if self.get_value() > other_card.get_value():\n",
    "            return self\n",
    "        else:\n",
    "            return other_card\n",
    "\n",
    "class CardState(Enum):\n",
    "    NOT_IN_GAME_YET = 0\n",
    "    BRISCOLA = 1\n",
    "    IN_P1_HAND = 2\n",
    "    IN_P2_HAND = 3\n",
    "    PLAYED = 4\n",
    "    PLAYED_IN_PREVIOUS_TURNS = 5\n",
    "\n",
    "class Agent:\n",
    "    \"\"\"\n",
    "    BriscolAI default Agent using DQN technique.\n",
    "    \"\"\"\n",
    "    def __init__(self, gamma: float, memory_limit: int = 1000):\n",
    "        # Hyper-parameters\n",
    "        self.gamma = gamma\n",
    "\n",
    "        def create_model():\n",
    "            model = keras.Sequential(\n",
    "                [\n",
    "                    layers.Input(shape=(40, 40)),\n",
    "                    layers.Flatten(),\n",
    "                    layers.Dense(32, activation='relu'),\n",
    "                    layers.Dense(32, activation='relu'),\n",
    "                    layers.Dense(32, activation='relu'),\n",
    "                    layers.Dense(32, activation='relu'),\n",
    "                    layers.Dense(units=3, activation='softmax')\n",
    "                ]\n",
    "            )\n",
    "            # You might try other losses such as MSE loss.\n",
    "            model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "            return model\n",
    "\n",
    "        # Create the action and target networks\n",
    "        self.action_model = create_model()\n",
    "        self.target_model = create_model()\n",
    "        self.target_model.set_weights(self.action_model.get_weights())\n",
    "\n",
    "        # State variables\n",
    "        self.previous_state = None\n",
    "        self.state = None\n",
    "\n",
    "        # Replay memory as a list of experiences\n",
    "        self.memory = []\n",
    "        self.memory_limit = memory_limit\n",
    "\n",
    "    def set_state(self, state: np.ndarray):\n",
    "        \"\"\"\n",
    "        Set the new state and automatically update the previous state.\n",
    "        \"\"\"\n",
    "        if self.state is None:\n",
    "            self.previous_state = state\n",
    "        else:\n",
    "            self.previous_state = self.state\n",
    "        self.state = state\n",
    "\n",
    "    def get_state(self) -> np.ndarray:\n",
    "        return np.copy(self.state)\n",
    "\n",
    "    def get_previous_state(self) -> np.ndarray:\n",
    "        return self.previous_state\n",
    "\n",
    "    def get_action(self) -> int:\n",
    "        state_input = self.state.reshape(-1, 40, 40)\n",
    "        q_values = self.action_model.predict(state_input, verbose=0)[0]\n",
    "        return np.argmax(q_values)\n",
    "\n",
    "    def save_in_memory(self, game_id: int, player: int, state: np.ndarray, action: int, reward: int, new_state: np.ndarray, done: bool):\n",
    "        # If memory exceeds the limit, drop the oldest half\n",
    "        if len(self.memory) >= self.memory_limit:\n",
    "            self.memory = self.memory[int(self.memory_limit / 2):]\n",
    "        experience = {\n",
    "            \"game_id\": game_id,\n",
    "            \"player\": player,\n",
    "            \"current_state\": state,\n",
    "            \"action\": action,\n",
    "            \"reward\": reward,\n",
    "            \"next_state\": new_state,\n",
    "            \"done\": done\n",
    "        }\n",
    "        self.memory.append(experience)\n",
    "\n",
    "    def train(self, batch_size: int = 30):\n",
    "        if len(self.memory) < batch_size:\n",
    "            return  # not enough samples yet\n",
    "\n",
    "        # Randomly sample a batch of experiences\n",
    "        batch_sample = random.sample(self.memory, batch_size)\n",
    "\n",
    "        # Build training batches\n",
    "        states = np.array([exp[\"current_state\"] for exp in batch_sample]).reshape(batch_size, 40, 40)\n",
    "        targets = self.action_model.predict(states, verbose=0)\n",
    "\n",
    "        for i, exp in enumerate(batch_sample):\n",
    "            # Predict target Q-values for the next state\n",
    "            next_state = exp[\"next_state\"].reshape(1, 40, 40)\n",
    "            q_target_next = self.target_model.predict(next_state, verbose=0)[0]\n",
    "            if not exp[\"done\"]:\n",
    "                target_value = exp[\"reward\"] + self.gamma * np.amax(q_target_next)\n",
    "            else:\n",
    "                target_value = exp[\"reward\"]\n",
    "            targets[i][exp[\"action\"]] = target_value\n",
    "\n",
    "        # Train on the batch\n",
    "        self.action_model.train_on_batch(states, targets)\n",
    "\n",
    "class Briscola:\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def __str__(self):\n",
    "        out = f'''Cards in the deck: {len(self.deck) + 1} \n",
    "Briscola: {self.briscola_card} \n",
    "Played Card: {self.played_card}\\n\\n'''\n",
    "        out += 'Your hand:\\n'\n",
    "        for idx, card in enumerate(self.p2_hand):\n",
    "            out += f'{idx}) {card}\\n'\n",
    "        return out\n",
    "\n",
    "    def get_P1_state(self) -> np.ndarray:\n",
    "        p1_state = np.copy(self.state)\n",
    "        p1_state[p1_state == CardState.IN_P2_HAND.value] = CardState.NOT_IN_GAME_YET.value\n",
    "        return p1_state\n",
    "\n",
    "    def get_P2_state(self) -> np.ndarray:\n",
    "        p2_state = np.copy(self.state)\n",
    "        p2_state[p2_state == CardState.IN_P1_HAND.value] = CardState.NOT_IN_GAME_YET.value\n",
    "        return p2_state\n",
    "\n",
    "    @staticmethod\n",
    "    def print_state(state):\n",
    "        # Utility function to save a state as csv\n",
    "        df = pd.DataFrame(state)\n",
    "        df.to_csv('data.csv', index=False)\n",
    "\n",
    "    def draw_card(self) -> Card:\n",
    "        \"\"\"\n",
    "        Each player draws from the deck, removing cards from the deck list.\n",
    "        \"\"\"\n",
    "        if len(self.deck) == 0:\n",
    "            self.briscola_drawn = True\n",
    "            return self.briscola_card\n",
    "        return self.deck.pop(0)\n",
    "\n",
    "    def create_deck(self) -> list:\n",
    "        \"\"\"\n",
    "        Create a new deck with cards in random order.\n",
    "        \"\"\"\n",
    "        deck = [Card(rank, seed) for rank in range(10) for seed in range(4)]\n",
    "        np.random.shuffle(deck)\n",
    "        return deck\n",
    "\n",
    "    def fight(self, first_card: Card, second_card: Card):\n",
    "        \"\"\"\n",
    "        Tells who wins between the two cards.\n",
    "        \"\"\"\n",
    "        if first_card.seed == second_card.seed:\n",
    "            return first_card.compare_cards(second_card)\n",
    "        if first_card.seed == self.briscola_card.seed:\n",
    "            return first_card\n",
    "        if second_card.seed == self.briscola_card.seed:\n",
    "            return second_card\n",
    "        return first_card\n",
    "\n",
    "    def fight_hash(self, first_card_hash: int, second_card_hash: int):\n",
    "        \"\"\"\n",
    "        Determines the winning card based on their hash.\n",
    "        Returns the hash of the winning card.\n",
    "        \"\"\"\n",
    "        # If same suit, use a \"power\" lookup\n",
    "        if first_card_hash // 10 == second_card_hash // 10:\n",
    "            power = {\n",
    "                0: 9,  # Ace\n",
    "                1: 0,  # Two\n",
    "                2: 8,  # Three\n",
    "                3: 1,  # Four\n",
    "                4: 2,  # Five\n",
    "                5: 3,  # Six\n",
    "                6: 4,  # Seven\n",
    "                7: 5,  # Knave\n",
    "                8: 6,  # Knight\n",
    "                9: 7   # King\n",
    "            }\n",
    "            # Compare power and return winning card's hash\n",
    "            if power[first_card_hash % 10] > power[second_card_hash % 10]:\n",
    "                return first_card_hash\n",
    "            else:\n",
    "                return second_card_hash\n",
    "\n",
    "        # If different suit, check for trump suit (briscola)\n",
    "        if first_card_hash // 10 == self.briscola_card.seed:\n",
    "            return first_card_hash\n",
    "        if second_card_hash // 10 == self.briscola_card.seed:\n",
    "            return second_card_hash\n",
    "        return first_card_hash\n",
    "\n",
    "    def reset(self, ai_turn: bool = None):\n",
    "        \"\"\"Reset the current environment.\"\"\"\n",
    "        self.deck = self.create_deck()\n",
    "        self.p1_hand = []\n",
    "        self.p2_hand = []\n",
    "        self.p1_hand.append(self.draw_card())\n",
    "        self.p1_hand.append(self.draw_card())\n",
    "        self.p1_hand.append(self.draw_card())\n",
    "        self.p2_hand.append(self.draw_card())\n",
    "        self.p2_hand.append(self.draw_card())\n",
    "        self.p2_hand.append(self.draw_card())\n",
    "        self.briscola_card = self.draw_card()\n",
    "        self.briscola_drawn = False\n",
    "\n",
    "        # Initialize scores\n",
    "        self.p1_score, self.p2_score = 0, 0\n",
    "        # Choose who starts\n",
    "        self.turn = 0 if ai_turn is None else int(ai_turn)\n",
    "        self.turn_number = 0\n",
    "\n",
    "        # Create the state: a 40x40 board\n",
    "        self.state = np.full((40, 40), CardState.NOT_IN_GAME_YET.value)\n",
    "        self.state[hash(self.briscola_card), :] = CardState.BRISCOLA.value\n",
    "\n",
    "        for card in self.p1_hand:\n",
    "            self.state[hash(card), 0] = CardState.IN_P1_HAND.value\n",
    "        for card in self.p2_hand:\n",
    "            self.state[hash(card), 0] = CardState.IN_P2_HAND.value\n",
    "\n",
    "        self.played_card = None\n",
    "        self.episode_ended = False\n",
    "\n",
    "    def step(self, action: int):\n",
    "        \"\"\"Apply action and return new state, reward, and done flag.\"\"\"\n",
    "        # Check for invalid action\n",
    "        current_hand = self.p1_hand if self.turn == 0 else self.p2_hand\n",
    "        if action < 0 or action >= len(current_hand):\n",
    "            return self.state, -10000, False\n",
    "\n",
    "        # Copy previous state column (simulate time progression)\n",
    "        if self.turn_number > 0:\n",
    "            self.state[:, self.turn_number] = self.state[:, self.turn_number - 1]\n",
    "\n",
    "        chosen_card = current_hand[action]\n",
    "        reward = 0\n",
    "        # By default, the second card played determines the round\n",
    "        winner = (self.turn + 1) % 2\n",
    "\n",
    "        if self.turn_number % 2 == 0:\n",
    "            # First card of the round\n",
    "            # Update any previously played cards\n",
    "            self.state[self.state[:, self.turn_number] == CardState.PLAYED.value, self.turn_number] = CardState.PLAYED_IN_PREVIOUS_TURNS.value\n",
    "            self.played_card = chosen_card\n",
    "        else:\n",
    "            # Second card: decide winner based on fight_hash\n",
    "            winning_hash = self.fight_hash(hash(self.played_card), hash(chosen_card))\n",
    "            winner = self.turn if winning_hash == hash(chosen_card) else (self.turn + 1) % 2\n",
    "            reward = Card.get_value_from_hash(hash(chosen_card)) + Card.get_value_from_hash(hash(self.played_card))\n",
    "\n",
    "        # Mark the played card in the state\n",
    "        self.state[hash(chosen_card), self.turn_number] = CardState.PLAYED.value\n",
    "\n",
    "        if self.turn_number % 2 != 0:\n",
    "            # End of round: update scores and draw new cards if available\n",
    "            if winner == 0:\n",
    "                self.p1_score += reward\n",
    "                if not self.briscola_drawn:\n",
    "                    self.p1_hand.append(self.draw_card())\n",
    "                    self.p2_hand.append(self.draw_card())\n",
    "            else:\n",
    "                self.p2_score += reward\n",
    "                if not self.briscola_drawn:\n",
    "                    self.p2_hand.append(self.draw_card())\n",
    "                    self.p1_hand.append(self.draw_card())\n",
    "            if not self.briscola_drawn:\n",
    "                self.state[hash(self.p1_hand[-1]), self.turn_number] = CardState.IN_P1_HAND.value\n",
    "                self.state[hash(self.p2_hand[-1]), self.turn_number] = CardState.IN_P2_HAND.value\n",
    "            self.played_card = None\n",
    "\n",
    "        # Remove the played card from the corresponding hand\n",
    "        if self.turn == 0:\n",
    "            self.p1_hand.pop(action)\n",
    "        else:\n",
    "            self.p2_hand.pop(action)\n",
    "\n",
    "        self.turn_number += 1\n",
    "        if winner != self.turn:\n",
    "            self.turn = (self.turn + 1) % 2\n",
    "\n",
    "        self.episode_ended = (len(self.p1_hand) == 0 and len(self.p2_hand) == 0)\n",
    "        return self.state, reward, self.episode_ended\n",
    "\n",
    "    def is_playing(self):\n",
    "        return not self.episode_ended\n",
    "\n",
    "    def get_winner(self):\n",
    "        if self.p1_score > self.p2_score:\n",
    "            return 0\n",
    "        elif self.p2_score > self.p1_score:\n",
    "            return 1\n",
    "        return 2\n",
    "\n",
    "# -------------------------\n",
    "# Training parameters\n",
    "total_episodes = 5000        # Total episodes\n",
    "gamma = 0.99                 # Discount factor\n",
    "\n",
    "# Exploration parameters\n",
    "epsilon = 1.0                # Exploration rate\n",
    "epsilon_min = 0.01           # Minimum exploration probability\n",
    "epsilon_decay = 0.001        # Exponential decay rate for exploration prob\n",
    "precalc_epsilon_decay = np.exp(-epsilon_decay)\n",
    "\n",
    "# System parameters\n",
    "memory_limit = 500           # Memory limit for the agent\n",
    "saving_rate = 100            # Saving frequency (in episodes)\n",
    "\n",
    "# Rewards history for plotting improvements\n",
    "rewards = []\n",
    "\n",
    "# Create the agent\n",
    "briscolAI = Agent(gamma, memory_limit)\n",
    "\n",
    "for episode in range(1, total_episodes+1):\n",
    "    print(f\"Episode: {episode}/{total_episodes} | Epsilon: {epsilon:.4f}\")\n",
    "    game = Briscola()\n",
    "\n",
    "    while game.is_playing():\n",
    "        # Select state depending on whose turn it is\n",
    "        current_state = game.get_P1_state() if game.turn == 0 else game.get_P2_state()\n",
    "        briscolAI.set_state(current_state)\n",
    "        # Choose action: exploration vs. exploitation\n",
    "        current_hand = game.p1_hand if game.turn == 0 else game.p2_hand\n",
    "        if np.random.uniform(0, 1) < epsilon:\n",
    "            action = np.random.randint(0, len(current_hand))\n",
    "        else:\n",
    "            action = briscolAI.get_action()\n",
    "        new_state, reward, episode_ended = game.step(action)\n",
    "        # Note: the state for saving memory is chosen before the turn change.\n",
    "        next_state = game.get_P1_state() if game.turn == 1 else game.get_P2_state()\n",
    "        briscolAI.save_in_memory(episode, game.turn, briscolAI.get_previous_state(), action, reward, next_state, not game.is_playing())\n",
    "\n",
    "    # Optionally adjust rewards for the last session in memory\n",
    "    last_session_id = episode\n",
    "    winning_player = game.get_winner()\n",
    "    score_difference = abs(game.p1_score - game.p2_score)\n",
    "    # Iterate backwards over memory and update rewards for experiences from the current game\n",
    "    for exp in reversed(briscolAI.memory):\n",
    "        if exp[\"game_id\"] != last_session_id:\n",
    "            break\n",
    "        if winning_player != 2:  # not a draw\n",
    "            if exp[\"player\"] == winning_player:\n",
    "                exp[\"reward\"] += score_difference\n",
    "            else:\n",
    "                exp[\"reward\"] -= score_difference\n",
    "\n",
    "    print(f\"Winner: {winning_player}, Score p1: {game.p1_score}, Score p2: {game.p2_score}\")\n",
    "    briscolAI.train()\n",
    "    # Save the model every saving_rate episodes\n",
    "    if episode % saving_rate == 0:\n",
    "        briscolAI.action_model.save('model.h5')\n",
    "\n",
    "    epsilon *= precalc_epsilon_decay\n",
    "    if epsilon < epsilon_min:\n",
    "        epsilon = epsilon_min\n",
    "\n",
    "    rewards.append(score_difference)\n",
    "\n",
    "print(\"Average score difference over time: \" + str(sum(rewards)/len(rewards)))\n",
    "plt.plot(rewards)\n",
    "plt.xlabel('Number of games')\n",
    "plt.ylabel('Score difference')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# Play the game interactively\n",
    "# For example, in a Jupyter or Colab environment you might do:\n",
    "game = Briscola()\n",
    "ai_turn = np.random.uniform(0, 1) < 0.5\n",
    "game.reset(ai_turn)\n",
    "\n",
    "while game.is_playing():\n",
    "    print(\"---------------------------------------------\")\n",
    "    print(game)\n",
    "    previous_played_card = game.played_card\n",
    "\n",
    "    if ai_turn:\n",
    "        print(\"Player turn:\")\n",
    "        print(f\"Select the card index (e.g., 0 to select {game.p2_hand[0]}):\")\n",
    "        try:\n",
    "            action = int(input())\n",
    "        except ValueError:\n",
    "            print(\"Invalid input, try again.\")\n",
    "            continue\n",
    "        if action < 0 or action >= len(game.p2_hand):\n",
    "            print(\"Invalid action index, try again.\")\n",
    "            continue\n",
    "        current_played_card = game.p2_hand[action]\n",
    "        print(f\"Player played {current_played_card}\\n\")\n",
    "        new_state, reward, episode_ended = game.step(action)\n",
    "    else:\n",
    "        print(\"BriscolAI turn:\")\n",
    "        action = np.random.randint(0, len(game.p1_hand))\n",
    "        current_played_card = game.p1_hand[action]\n",
    "        print(f\"BriscolAI played {current_played_card}\\n\")\n",
    "        new_state, reward, episode_ended = game.step(action)\n",
    "    print(f\"Game turn: {game.turn_number}\")\n",
    "    if game.turn_number % 2 == 0 and previous_played_card is not None:\n",
    "        if game.turn == 0:\n",
    "            print(f\"BriscolAI took {previous_played_card} with {current_played_card}\")\n",
    "        else:\n",
    "            print(f\"Human took {previous_played_card} with {current_played_card}\")\n",
    "    ai_turn = not ai_turn\n",
    "    # If running in an interactive environment, you might clear output here.\n",
    "    # For example: from IPython.display import clear_output; clear_output(wait=True)\n",
    "\n",
    "print(game)\n",
    "winner = game.get_winner()\n",
    "\n",
    "if winner == 2:\n",
    "    print(\"It's a draw!\")\n",
    "elif winner == 0:\n",
    "    print(\"BriscolAI wins!\")\n",
    "else:\n",
    "    print(\"You win!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
